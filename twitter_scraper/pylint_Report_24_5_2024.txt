************* Module manage
manage.py:11:8: C0415: Import outside toplevel (django.core.management.execute_from_command_line) (import-outside-toplevel)
************* Module scraper.admin
scraper\admin.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\admin.py:1:0: W0611: Unused admin imported from django.contrib (unused-import)
************* Module scraper.apps
scraper\apps.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\apps.py:4:0: C0115: Missing class docstring (missing-class-docstring)
************* Module scraper.models
scraper\models.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\models.py:1:0: W0611: Unused models imported from django.db (unused-import)
************* Module scraper.serializers
scraper\serializers.py:26:0: C0304: Final newline missing (missing-final-newline)
scraper\serializers.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\serializers.py:4:0: C0115: Missing class docstring (missing-class-docstring)
scraper\serializers.py:4:0: W0223: Method 'create' is abstract in class 'BaseSerializer' but is not overridden in child class 'TwitterProfileSerializers' (abstract-method)
scraper\serializers.py:4:0: W0223: Method 'update' is abstract in class 'BaseSerializer' but is not overridden in child class 'TwitterProfileSerializers' (abstract-method)
scraper\serializers.py:8:0: C0115: Missing class docstring (missing-class-docstring)
scraper\serializers.py:8:0: W0223: Method 'create' is abstract in class 'BaseSerializer' but is not overridden in child class 'TweetHashtagSerializer' (abstract-method)
scraper\serializers.py:8:0: W0223: Method 'update' is abstract in class 'BaseSerializer' but is not overridden in child class 'TweetHashtagSerializer' (abstract-method)
scraper\serializers.py:12:0: C0115: Missing class docstring (missing-class-docstring)
scraper\serializers.py:12:0: W0223: Method 'create' is abstract in class 'BaseSerializer' but is not overridden in child class 'TweetUrlSerializer' (abstract-method)
scraper\serializers.py:12:0: W0223: Method 'update' is abstract in class 'BaseSerializer' but is not overridden in child class 'TweetUrlSerializer' (abstract-method)
scraper\serializers.py:17:4: C0116: Missing function or method docstring (missing-function-docstring)
scraper\serializers.py:23:12: W0707: Consider explicitly re-raising using 'except ValueError as exc' and 'raise serializers.ValidationError('Post ID must be an integer') from exc' (raise-missing-from)
************* Module scraper.tests
scraper\tests.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\tests.py:1:0: W0611: Unused TestCase imported from django.test (unused-import)
************* Module scraper.urls
scraper\urls.py:5:0: C0301: Line too long (113/100) (line-too-long)
scraper\urls.py:6:0: C0301: Line too long (111/100) (line-too-long)
scraper\urls.py:7:0: C0301: Line too long (104/100) (line-too-long)
scraper\urls.py:9:0: C0301: Line too long (114/100) (line-too-long)
scraper\urls.py:1:0: C0114: Missing module docstring (missing-module-docstring)
************* Module scraper.utils
scraper\utils.py:54:0: C0301: Line too long (105/100) (line-too-long)
scraper\utils.py:61:22: C0303: Trailing whitespace (trailing-whitespace)
scraper\utils.py:80:22: C0303: Trailing whitespace (trailing-whitespace)
scraper\utils.py:106:0: C0301: Line too long (111/100) (line-too-long)
scraper\utils.py:118:0: C0301: Line too long (119/100) (line-too-long)
scraper\utils.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\utils.py:23:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\utils.py:29:0: C0103: Function name "twitterLogin_auth" doesn't conform to snake_case naming style (invalid-name)
scraper\utils.py:52:8: W0107: Unnecessary pass statement (unnecessary-pass)
scraper\utils.py:62:8: W0107: Unnecessary pass statement (unnecessary-pass)
scraper\utils.py:139:70: R1735: Consider using '{"indent": 2}' instead of a call to 'dict'. (use-dict-literal)
scraper\utils.py:4:0: C0411: standard import "time.sleep" should be placed before third party import "selenium.webdriver.common.by.By" (wrong-import-order)
scraper\utils.py:5:0: C0411: standard import "time" should be placed before third party import "selenium.webdriver.common.by.By" (wrong-import-order)
scraper\utils.py:8:0: C0411: standard import "typing.Optional" should be placed before third party imports "selenium.webdriver.common.by.By", "selenium.common.exceptions.NoSuchElementException", "django.http.JsonResponse" (wrong-import-order)
scraper\utils.py:10:0: C0411: standard import "json" should be placed before third party imports "selenium.webdriver.common.by.By", "selenium.common.exceptions.NoSuchElementException", "django.http.JsonResponse", "rest_framework.status" (wrong-import-order)
scraper\utils.py:11:0: C0411: standard import "functools.wraps" should be placed before third party imports "selenium.webdriver.common.by.By", "selenium.common.exceptions.NoSuchElementException", "django.http.JsonResponse", "rest_framework.status" (wrong-import-order)
scraper\utils.py:4:0: W0611: Unused sleep imported from time (unused-import)
scraper\utils.py:9:0: W0611: Unused status imported from rest_framework (unused-import)
scraper\utils.py:11:0: W0611: Unused wraps imported from functools (unused-import)
************* Module scraper.views
scraper\views.py:29:0: W0311: Bad indentation. Found 16 spaces, expected 4 (bad-indentation)
scraper\views.py:30:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:32:0: C0301: Line too long (136/100) (line-too-long)
scraper\views.py:32:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:33:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:34:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:35:0: W0311: Bad indentation. Found 16 spaces, expected 4 (bad-indentation)
scraper\views.py:37:0: C0301: Line too long (104/100) (line-too-long)
scraper\views.py:37:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:38:0: C0301: Line too long (105/100) (line-too-long)
scraper\views.py:38:0: W0311: Bad indentation. Found 20 spaces, expected 8 (bad-indentation)
scraper\views.py:39:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:45:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:49:0: C0301: Line too long (106/100) (line-too-long)
scraper\views.py:58:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:59:0: C0301: Line too long (176/100) (line-too-long)
scraper\views.py:63:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:64:0: C0301: Line too long (258/100) (line-too-long)
scraper\views.py:65:0: C0301: Line too long (222/100) (line-too-long)
scraper\views.py:69:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:73:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:76:30: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:77:0: C0301: Line too long (159/100) (line-too-long)
scraper\views.py:81:0: C0301: Line too long (102/100) (line-too-long)
scraper\views.py:110:0: C0301: Line too long (107/100) (line-too-long)
scraper\views.py:131:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:135:0: C0301: Line too long (107/100) (line-too-long)
scraper\views.py:143:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:145:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:147:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:154:0: C0301: Line too long (102/100) (line-too-long)
scraper\views.py:181:0: C0301: Line too long (107/100) (line-too-long)
scraper\views.py:182:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:202:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:206:0: C0301: Line too long (107/100) (line-too-long)
scraper\views.py:210:0: C0301: Line too long (145/100) (line-too-long)
scraper\views.py:214:0: C0301: Line too long (178/100) (line-too-long)
scraper\views.py:229:0: C0301: Line too long (105/100) (line-too-long)
scraper\views.py:241:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:246:0: C0301: Line too long (129/100) (line-too-long)
scraper\views.py:259:0: C0301: Line too long (102/100) (line-too-long)
scraper\views.py:261:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:266:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:269:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:291:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:294:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:308:32: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:310:38: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:313:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:320:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:324:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:327:0: C0301: Line too long (122/100) (line-too-long)
scraper\views.py:328:0: C0301: Line too long (127/100) (line-too-long)
scraper\views.py:329:0: C0301: Line too long (170/100) (line-too-long)
scraper\views.py:330:0: C0301: Line too long (125/100) (line-too-long)
scraper\views.py:331:0: C0301: Line too long (170/100) (line-too-long)
scraper\views.py:332:0: C0301: Line too long (114/100) (line-too-long)
scraper\views.py:334:0: C0301: Line too long (117/100) (line-too-long)
scraper\views.py:339:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:356:0: C0301: Line too long (103/100) (line-too-long)
scraper\views.py:357:0: C0301: Line too long (120/100) (line-too-long)
scraper\views.py:361:0: C0301: Line too long (104/100) (line-too-long)
scraper\views.py:362:0: C0301: Line too long (126/100) (line-too-long)
scraper\views.py:363:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:365:0: C0301: Line too long (110/100) (line-too-long)
scraper\views.py:366:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:371:0: C0301: Line too long (104/100) (line-too-long)
scraper\views.py:372:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:392:0: C0301: Line too long (108/100) (line-too-long)
scraper\views.py:394:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:435:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:447:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:453:0: C0301: Line too long (122/100) (line-too-long)
scraper\views.py:454:0: C0301: Line too long (111/100) (line-too-long)
scraper\views.py:456:0: C0301: Line too long (109/100) (line-too-long)
scraper\views.py:458:0: C0301: Line too long (114/100) (line-too-long)
scraper\views.py:460:0: C0301: Line too long (117/100) (line-too-long)
scraper\views.py:487:0: C0301: Line too long (120/100) (line-too-long)
scraper\views.py:492:0: C0301: Line too long (126/100) (line-too-long)
scraper\views.py:495:0: C0301: Line too long (110/100) (line-too-long)
scraper\views.py:496:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:499:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:501:0: C0301: Line too long (111/100) (line-too-long)
scraper\views.py:522:0: C0301: Line too long (102/100) (line-too-long)
scraper\views.py:524:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\views.py:23:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:27:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:27:0: C0103: Function name "retry_Exception" doesn't conform to snake_case naming style (invalid-name)
scraper\views.py:29:16: R1705: Unnecessary "else" after "return", remove the "else" and de-indent the code inside it (no-else-return)
scraper\views.py:33:20: W0104: Statement seems to have no effect (pointless-statement)
scraper\views.py:37:26: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:42:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:42:0: R0914: Too many local variables (18/15) (too-many-locals)
scraper\views.py:56:14: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:61:14: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:67:14: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:80:54: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:47:13: W0641: Possibly unused variable 'message' (possibly-unused-variable)
scraper\views.py:115:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:115:0: C0103: Function name "get_Tweeted_via_profile_name" doesn't conform to snake_case naming style (invalid-name)
scraper\views.py:128:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:128:0: R0914: Too many local variables (16/15) (too-many-locals)
scraper\views.py:153:54: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:133:13: W0641: Possibly unused variable 'message' (possibly-unused-variable)
scraper\views.py:150:16: W0641: Possibly unused variable 'article' (possibly-unused-variable)
scraper\views.py:185:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:199:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views.py:204:13: W0641: Possibly unused variable 'message' (possibly-unused-variable)
scraper\views.py:275:0: R0914: Too many local variables (20/15) (too-many-locals)
scraper\views.py:309:18: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:310:18: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:316:18: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views.py:299:17: W0641: Possibly unused variable 'message' (possibly-unused-variable)
scraper\views.py:403:0: R0914: Too many local variables (21/15) (too-many-locals)
scraper\views.py:428:17: W0641: Possibly unused variable 'message' (possibly-unused-variable)
scraper\views.py:449:16: W0641: Possibly unused variable 'tweet_elements' (possibly-unused-variable)
scraper\views.py:3:0: C0411: standard import "time.sleep" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views.py:4:0: C0411: standard import "time" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views.py:5:0: C0411: standard import "random" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views.py:6:0: C0411: standard import "threading" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views.py:15:0: C0411: standard import "concurrent.futures.ThreadPoolExecutor" should be placed before third party imports "django.utils.timezone", "rest_framework.status", "rest_framework.decorators.api_view" (...) "selenium.webdriver.common.keys.Keys", "selenium.webdriver.support.ui.WebDriverWait", "selenium.webdriver.support.expected_conditions" (wrong-import-order)
scraper\views.py:1:0: W0611: Unused import json (unused-import)
scraper\views.py:3:0: W0611: Unused sleep imported from time (unused-import)
scraper\views.py:4:0: W0611: Unused import time (unused-import)
scraper\views.py:5:0: W0611: Unused import random (unused-import)
************* Module scraper.views_old
scraper\views_old.py:50:0: C0301: Line too long (108/100) (line-too-long)
scraper\views_old.py:56:0: C0301: Line too long (114/100) (line-too-long)
scraper\views_old.py:61:0: C0301: Line too long (174/100) (line-too-long)
scraper\views_old.py:66:0: C0301: Line too long (110/100) (line-too-long)
scraper\views_old.py:75:0: C0301: Line too long (222/100) (line-too-long)
scraper\views_old.py:76:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views_old.py:79:0: C0301: Line too long (220/100) (line-too-long)
scraper\views_old.py:85:0: C0301: Line too long (111/100) (line-too-long)
scraper\views_old.py:86:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\views_old.py:97:0: C0301: Line too long (112/100) (line-too-long)
scraper\views_old.py:102:0: C0301: Line too long (153/100) (line-too-long)
scraper\views_old.py:106:0: C0301: Line too long (101/100) (line-too-long)
scraper\views_old.py:108:0: C0301: Line too long (190/100) (line-too-long)
scraper\views_old.py:110:0: C0301: Line too long (185/100) (line-too-long)
scraper\views_old.py:126:0: C0301: Line too long (109/100) (line-too-long)
scraper\views_old.py:128:0: C0301: Line too long (106/100) (line-too-long)
scraper\views_old.py:143:0: C0301: Line too long (107/100) (line-too-long)
scraper\views_old.py:160:0: C0301: Line too long (101/100) (line-too-long)
scraper\views_old.py:161:0: C0301: Line too long (138/100) (line-too-long)
scraper\views_old.py:162:0: C0301: Line too long (136/100) (line-too-long)
scraper\views_old.py:172:0: C0301: Line too long (108/100) (line-too-long)
scraper\views_old.py:178:0: C0301: Line too long (134/100) (line-too-long)
scraper\views_old.py:186:0: C0301: Line too long (112/100) (line-too-long)
scraper\views_old.py:193:0: C0301: Line too long (190/100) (line-too-long)
scraper\views_old.py:195:0: C0301: Line too long (185/100) (line-too-long)
scraper\views_old.py:211:0: C0301: Line too long (108/100) (line-too-long)
scraper\views_old.py:212:0: C0301: Line too long (107/100) (line-too-long)
scraper\views_old.py:240:0: C0301: Line too long (138/100) (line-too-long)
scraper\views_old.py:241:0: C0301: Line too long (147/100) (line-too-long)
scraper\views_old.py:248:0: C0301: Line too long (180/100) (line-too-long)
scraper\views_old.py:250:0: C0301: Line too long (139/100) (line-too-long)
scraper\views_old.py:255:0: C0301: Line too long (108/100) (line-too-long)
scraper\views_old.py:259:0: C0301: Line too long (172/100) (line-too-long)
scraper\views_old.py:264:0: C0301: Line too long (108/100) (line-too-long)
scraper\views_old.py:278:0: C0301: Line too long (105/100) (line-too-long)
scraper\views_old.py:281:0: C0301: Line too long (114/100) (line-too-long)
scraper\views_old.py:297:0: C0301: Line too long (105/100) (line-too-long)
scraper\views_old.py:300:0: C0301: Line too long (103/100) (line-too-long)
scraper\views_old.py:323:0: C0301: Line too long (118/100) (line-too-long)
scraper\views_old.py:328:0: C0301: Line too long (118/100) (line-too-long)
scraper\views_old.py:329:0: C0301: Line too long (123/100) (line-too-long)
scraper\views_old.py:330:0: C0301: Line too long (169/100) (line-too-long)
scraper\views_old.py:331:0: C0301: Line too long (121/100) (line-too-long)
scraper\views_old.py:332:0: C0301: Line too long (167/100) (line-too-long)
scraper\views_old.py:333:0: C0301: Line too long (110/100) (line-too-long)
scraper\views_old.py:335:0: C0301: Line too long (113/100) (line-too-long)
scraper\views_old.py:351:0: C0301: Line too long (109/100) (line-too-long)
scraper\views_old.py:352:0: C0301: Line too long (104/100) (line-too-long)
scraper\views_old.py:364:0: C0301: Line too long (111/100) (line-too-long)
scraper\views_old.py:370:0: C0301: Line too long (119/100) (line-too-long)
scraper\views_old.py:375:0: C0301: Line too long (114/100) (line-too-long)
scraper\views_old.py:376:0: C0301: Line too long (119/100) (line-too-long)
scraper\views_old.py:377:0: C0301: Line too long (165/100) (line-too-long)
scraper\views_old.py:378:0: C0301: Line too long (117/100) (line-too-long)
scraper\views_old.py:379:0: C0301: Line too long (163/100) (line-too-long)
scraper\views_old.py:380:0: C0301: Line too long (106/100) (line-too-long)
scraper\views_old.py:382:0: C0301: Line too long (109/100) (line-too-long)
scraper\views_old.py:398:0: C0301: Line too long (109/100) (line-too-long)
scraper\views_old.py:399:0: C0301: Line too long (104/100) (line-too-long)
scraper\views_old.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\views_old.py:21:0: C0103: Function name "get_Tweeted_via_profile_name" doesn't conform to snake_case naming style (invalid-name)
scraper\views_old.py:21:0: R0914: Too many local variables (18/15) (too-many-locals)
scraper\views_old.py:21:0: R0911: Too many return statements (7/6) (too-many-return-statements)
scraper\views_old.py:45:17: W0612: Unused variable 'message' (unused-variable)
scraper\views_old.py:191:58: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
scraper\views_old.py:168:17: W0612: Unused variable 'message' (unused-variable)
scraper\views_old.py:188:20: W0612: Unused variable 'article' (unused-variable)
scraper\views_old.py:217:0: C0103: Function name "Twiiter_treding_hashtag" doesn't conform to snake_case naming style (invalid-name)
scraper\views_old.py:217:28: W0613: Unused argument 'request' (unused-argument)
scraper\views_old.py:244:13: W0612: Unused variable 'message' (unused-variable)
scraper\views_old.py:304:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views_old.py:304:0: R0914: Too many local variables (18/15) (too-many-locals)
scraper\views_old.py:310:17: W0612: Unused variable 'message' (unused-variable)
scraper\views_old.py:321:16: W0612: Unused variable 'tweet_elements' (unused-variable)
scraper\views_old.py:357:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\views_old.py:361:17: W0612: Unused variable 'message' (unused-variable)
scraper\views_old.py:3:0: C0411: standard import "time.sleep" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views_old.py:4:0: C0411: standard import "time" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views_old.py:5:0: C0411: standard import "random" should be placed before third party import "django.utils.timezone" (wrong-import-order)
scraper\views_old.py:15:0: C0411: third party import "selenium.webdriver.support.ui.WebDriverWait" should be placed before local imports "serializers.TwitterProfileSerializers", "utils.twitterLogin_auth", "web_driver.initialize_driver" (wrong-import-order)
scraper\views_old.py:16:0: C0411: third party import "selenium.webdriver.support.expected_conditions" should be placed before local imports "serializers.TwitterProfileSerializers", "utils.twitterLogin_auth", "web_driver.initialize_driver" (wrong-import-order)
scraper\views_old.py:17:0: C0411: third party import "selenium.common.exceptions.StaleElementReferenceException" should be placed before local imports "serializers.TwitterProfileSerializers", "utils.twitterLogin_auth", "web_driver.initialize_driver" (wrong-import-order)
scraper\views_old.py:1:0: W0611: Unused import json (unused-import)
scraper\views_old.py:3:0: W0611: Unused sleep imported from time (unused-import)
scraper\views_old.py:4:0: W0611: Unused import time (unused-import)
scraper\views_old.py:5:0: W0611: Unused import random (unused-import)
************* Module scraper.web_driver
scraper\web_driver.py:17:0: C0301: Line too long (122/100) (line-too-long)
scraper\web_driver.py:117:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\web_driver.py:127:0: C0303: Trailing whitespace (trailing-whitespace)
scraper\web_driver.py:1:0: C0114: Missing module docstring (missing-module-docstring)
scraper\web_driver.py:7:0: E0401: Unable to import 'webdriver_manager.chrome' (import-error)
scraper\web_driver.py:8:0: E0401: Unable to import 'fake_useragent' (import-error)
scraper\web_driver.py:12:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\web_driver.py:14:15: W3101: Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely (missing-timeout)
scraper\web_driver.py:100:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\web_driver.py:114:4: W0612: Unused variable 'capability' (unused-variable)
scraper\web_driver.py:137:0: C0116: Missing function or method docstring (missing-function-docstring)
scraper\web_driver.py:2:0: C0411: standard import "random" should be placed before third party import "selenium.webdriver" (wrong-import-order)
scraper\web_driver.py:3:0: C0411: standard import "ipaddress" should be placed before third party import "selenium.webdriver" (wrong-import-order)
scraper\web_driver.py:9:0: C0412: Imports from package selenium are not grouped (ungrouped-imports)
************* Module twitter_scraper.__init__
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[325:352]
==scraper.views_old:[326:350]
                tweet = driver.find_element(By.XPATH, "//div[@data-testid='tweetText']").text
                image_url = driver.find_element(By.CSS_SELECTOR, 'div[data-testid="tweetPhoto"] img').get_attribute('src')
                reply_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="reply"]').find_element(By.CSS_SELECTOR,
                                                                                                            'span[data-testid="app-text-transition-container"] span').text
                like_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="like"]').find_element(By.CSS_SELECTOR,
                                                                                                            'span[data-testid="app-text-transition-container"] span').text
                repost_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="retweet"]').find_element(
                    By.CSS_SELECTOR, 'span[data-testid="app-text-transition-container"] span').text
                bookmark_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="bookmark"]').find_element(
                    By.CSS_SELECTOR, 'span[data-testid="app-text-transition-container"] span').text
                driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')
                timestamp = driver.find_element(By.XPATH, "//time").get_attribute('datetime')
                views_count = driver.find_element(By.CSS_SELECTOR, 'span.css-1jxf684').text

                # Append the extracted data to the list
                data.append({
                    "username": request.data.get('user_name'),
                    "TweetContent": tweet,
                    "views_count": views_count,
                    "timestamp": timestamp,
                    "content_image": image_url,
                    "reply_count": reply_count,
                    "like_count": like_count,
                    "repost_count": repost_count,
                    "bookmark_count": bookmark_count
                })
 (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[457:482]
==scraper.views_old:[332:350]
                repost_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="retweet"]').find_element(
                    By.CSS_SELECTOR, 'span[data-testid="app-text-transition-container"] span').text
                bookmark_count = driver.find_element(By.CSS_SELECTOR, 'button[data-testid="bookmark"]').find_element(
                    By.CSS_SELECTOR, 'span[data-testid="app-text-transition-container"] span').text

                # Scroll to the bottom of the page to load additional content
                driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')

                # Extract timestamp and views count
                timestamp = driver.find_element(By.XPATH, "//time").get_attribute('datetime')
                views_count = driver.find_element(By.CSS_SELECTOR, 'span.css-1jxf684').text

                # Append scraped data to the list
                data.append({
                    "username": request.data.get('user_name'),
                    "TweetContent": tweet,
                    "views_count": views_count,
                    "timestamp": timestamp,
                    "content_image": image_url,
                    "reply_count": reply_count,
                    "like_count": like_count,
                    "repost_count": repost_count,
                    "bookmark_count": bookmark_count
                })
 (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[82:96]
==scraper.views_old:[110:124]
                data.append({
                    "Name": profile_name,
                    "UserTag": user_tag,
                    "Timestamp": timestamp,
                    "TweetContent": tweet,
                    "Reply": reply,
                    "Retweet": retweet,
                    "Likes": likes
                })
                driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')
                if len(data) > 5:
                    break
            break
 (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[156:166]
==scraper.views_old:[113:124]
                        "Timestamp": timestamp,
                        "TweetContent": tweet,
                        "Reply": reply,
                        "Retweet": retweet,
                        "Likes": likes
                    })
                    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')
                    if len(data) > 5:
                        break
                break
            # Save data to JSON file (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[218:228]
==scraper.views_old:[266:276]
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            random_sleep()  # Adjust sleep time as needed
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        # Find all trending topic elements (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[292:308]
==scraper.views_old:[307:314]
        driver = initialize_driver()
        post_ids = request.data.get('post_ids')
        success, message = twitterLogin_auth(driver)
        if success:
            random_sleep()
        data = []
        for post_id in post_ids: (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[85:92]
==scraper.views_old:[196:203]
                    "Timestamp": timestamp,
                    "TweetContent": tweet,
                    "Reply": reply,
                    "Retweet": retweet,
                    "Likes": likes
                })
                driver.execute_script('window.scrollTo(0,document.body.scrollHeight);') (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[155:163]
==scraper.views_old:[195:203]
                data.append({
                    "Timestamp": timestamp,
                    "TweetContent": tweet,
                    "Reply": reply,
                    "Retweet": retweet,
                    "Likes": likes
                })
                driver.execute_script('window.scrollTo(0,document.body.scrollHeight);') (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[148:153]
==scraper.views_old:[186:191]
        while True:
            for article in articles:
                timestamp = driver.find_element(By.XPATH, "//time").get_attribute('datetime')
                tweet = driver.find_element(By.XPATH, "//div[@data-testid='tweetText']").text
                reply = driver.find_element(By.XPATH, f'//*[@data-testid="reply"]').text (duplicate-code)
twitter_scraper\__init__.py:1:0: R0801: Similar lines in 2 files
==scraper.views:[136:141]
==scraper.views_old:[169:174]
            try:
                random_sleep()
                search_box = driver.find_element(By.XPATH, "//input[@data-testid='SearchBox_Search_Input']")
                search_box.send_keys(hashtags)
                search_box.send_keys(Keys.ENTER) (duplicate-code)

------------------------------------------------------------------
Your code has been rated at 5.80/10 (previous run: 5.80/10, +0.00)

